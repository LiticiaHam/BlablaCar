{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecce219-c495-4961-9633-e2ac934edff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/06 14:06:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/06 14:06:47 WARN TaskSetManager: Stage 0 contains a task of very large size (6673 KiB). The maximum recommended task size is 1000 KiB.\n",
      "ERROR:root:Exception while sending command.                         (0 + 1) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=59>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/local/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/pyspark/context.py\", line 292, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/pyspark/context.py\", line 1195, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o13.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur rencontrée : An error occurred while calling o48.save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/06 14:16:55 WARN TaskSetManager: Stage 1 contains a task of very large size (6673 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/09/06 14:44:07 WARN TaskSetManager: Stage 2 contains a task of very large size (6674 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialiser la session Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"get-data\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Clé d'API\n",
    "headers = {'Authorization': 'Token 9_YiYsUW93g6NExNmInqhA'}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Utiliser la date actuelle\n",
    "        date_today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Requête API\n",
    "        r = requests.get(f\"https://bus-api.blablacar.com/v1/fares?date={date_today}\", headers=headers)\n",
    "        \n",
    "        # Vérification du statut de la réponse\n",
    "        if r.status_code == 200:\n",
    "            # Convertir les données en DataFrame Spark\n",
    "            df = spark.createDataFrame(r.json()[\"fares\"]).withColumn(\"timestamp_ingestion\", current_timestamp())\n",
    "            \n",
    "            # Écriture des données\n",
    "            df.coalesce(1).write.format(\"json\").mode(\"overwrite\").save(\"hdfs://namenode:9000/data/data_bbc\")\n",
    "        else:\n",
    "            print(f\"Erreur lors de la récupération des données: {r.status_code}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur rencontrée : {e}\")\n",
    "    \n",
    "    # Pause de 10 min ( a modifier comme il nous semble)\n",
    "    sleep(600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee9416-353c-4f6f-8939-975fd48e0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rich\n",
    "from rich import print \n",
    "r = requests.get(f\"https://bus-api.blablacar.com/v1/fares?date=2024-09-06\", headers=headers).json()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f9126-986e-4e4b-b6d0-bf19400194f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
